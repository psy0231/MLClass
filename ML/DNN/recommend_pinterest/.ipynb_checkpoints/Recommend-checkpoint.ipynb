{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66382efe",
   "metadata": {},
   "source": [
    "## 추천 시스템: 5종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f86910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "# import cv2\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용\n",
    "from tensorflow.keras.layers import Dense       # 전결합\n",
    "from tensorflow.keras.layers import Dropout     # 특정 node를 사용안함.\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping   # 학습 자동 중지\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # 우수한 학습 모델 파일 저장\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.utils import to_categorical   # one-hot 엔코딩\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split # 학습셋과 테스트셋의 분리 지원\n",
    "from sklearn.model_selection import StratifiedKFold  # K겹 교차 검증\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "import platform \n",
    "# Windows, Linux, Darwin\n",
    "if (platform.system() == 'Windows'):  \n",
    "    rc('font', family=font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name())\n",
    "    path = '.' # Local\n",
    "else:    \n",
    "    rc('font', family='NanumBarunGothic')  # Ubuntu 18.04 기준 한글 처리\n",
    "    path = '/content/drive/My Drive/kd_ml/dnn/iris' # Colab\n",
    "\n",
    "os.chdir(path) # 기본 경로 설정\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12         # 글자 크기\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4) # 10:4의 그래프 비율\n",
    "plt.rcParams['axes.unicode_minus'] = False  # minus 부호는 unicode 적용시 한글이 깨짐으로 설정\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# gpu 사용시 런타임에서 필요한 양만큼의 GPU 메모리를 할당후 자동 증가 처리\n",
    "# OS 메모리도 초기화됨.\n",
    "# ---------------------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "    \n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7ead2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 26)\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      "  0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('./train.csv', delimiter=',', skiprows=1, dtype=np.float64)\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28faee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 25)\n",
      "(100,)\n",
      "[0. 1. 2. 3. 4. 0. 1. 2. 3. 4. 0. 1. 2. 3. 4.]\n",
      "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "X = data[:, 0:25]  # 독립 변수 25개\n",
    "Y = data[:, 25]    # 종속 변수, 26번째, 답\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y[:15])\n",
    "Y = Y.astype('int')\n",
    "print(Y[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e76610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0.]\n",
      "Y[0]: 0\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "Y_encoded = to_categorical(Y) \n",
    "print(X[0])              # Iris-setosa  0  [5.1 3.5 1.4 0.2]\n",
    "print('Y[0]:', Y[0])     # Y[0]의 값 0은 1 이 위치할 index로 사용 ★\n",
    "print(Y_encoded[0:5])      # Y[0]의 값 0은 1 이 위치할 index로 사용 ★"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de4be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "(18, 5)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 분할을 통한 훈련, 검증, 테스트 데이터의 분리\n",
    "seed = 0\n",
    "# 90%: 분할대기, 10%: 테스트\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(X, Y_encoded,\n",
    "                                                        stratify=Y_encoded,\n",
    "                                                        test_size=0.1,\n",
    "                                                        random_state=seed)\n",
    "# 나머지 데이터 90%를 분할, 80%: 훈련, 20%: 검증\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  stratify=y_train_all,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=seed)\n",
    "\n",
    "print(y_val)\n",
    "print(y_val.shape)\n",
    "# Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc2bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                520       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 1.3267 - accuracy: 0.2308\n",
      "Epoch 1: val_accuracy improved from -inf to 0.38889, saving model to .\\Pinterest.h5\n",
      "72/72 [==============================] - 3s 10ms/step - loss: 1.3088 - accuracy: 0.2500 - val_loss: 1.1295 - val_accuracy: 0.3889\n",
      "Epoch 2/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 1.0374 - accuracy: 0.4219\n",
      "Epoch 2: val_accuracy did not improve from 0.38889\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.0410 - accuracy: 0.4028 - val_loss: 0.8951 - val_accuracy: 0.3889\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.7083\n",
      "Epoch 3: val_accuracy improved from 0.38889 to 0.83333, saving model to .\\Pinterest.h5\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.8343 - accuracy: 0.7083 - val_loss: 0.6980 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.6476 - accuracy: 0.7794\n",
      "Epoch 4: val_accuracy improved from 0.83333 to 1.00000, saving model to .\\Pinterest.h5\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.6306 - accuracy: 0.7917 - val_loss: 0.4631 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 0.4013 - accuracy: 1.0000\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.2292 - accuracy: 1.0000\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.2284 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0710 - accuracy: 1.0000\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 9.8599e-04 - accuracy: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 9.8572e-04 - accuracy: 1.0000 - val_loss: 9.2721e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 9.3583e-04 - accuracy: 1.0000\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 9.1248e-04 - accuracy: 1.0000 - val_loss: 8.5641e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 8.4415e-04 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 8.4308e-04 - accuracy: 1.0000 - val_loss: 7.9234e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 7.7241e-04 - accuracy: 1.0000\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 7.8158e-04 - accuracy: 1.0000 - val_loss: 7.3549e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 7.2550e-04 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 7.2657e-04 - accuracy: 1.0000 - val_loss: 6.8344e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 6.8154e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 6.7547e-04 - accuracy: 1.0000 - val_loss: 6.3566e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 6.1773e-04 - accuracy: 1.0000\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 6.2856e-04 - accuracy: 1.0000 - val_loss: 5.9321e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 5.8283e-04 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 5.8624e-04 - accuracy: 1.0000 - val_loss: 5.5204e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 5.4219e-04 - accuracy: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 5.4554e-04 - accuracy: 1.0000 - val_loss: 5.1548e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.1007e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 5.1007e-04 - accuracy: 1.0000 - val_loss: 4.8181e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 4.6747e-04 - accuracy: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.7735e-04 - accuracy: 1.0000 - val_loss: 4.5195e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.4611e-04 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.4691e-04 - accuracy: 1.0000 - val_loss: 4.2149e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.1624e-04 - accuracy: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.1764e-04 - accuracy: 1.0000 - val_loss: 3.9460e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 3.9450e-04 - accuracy: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 3.9147e-04 - accuracy: 1.0000 - val_loss: 3.6933e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 3.7034e-04 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.6752e-04 - accuracy: 1.0000 - val_loss: 3.4668e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 3.5339e-04 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.4537e-04 - accuracy: 1.0000 - val_loss: 3.2626e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 3.4171e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.2533e-04 - accuracy: 1.0000 - val_loss: 3.0590e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 3.0893e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.0525e-04 - accuracy: 1.0000 - val_loss: 2.8799e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 2.9436e-04 - accuracy: 1.0000\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.8740e-04 - accuracy: 1.0000 - val_loss: 2.7101e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.7054e-04 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.7054e-04 - accuracy: 1.0000 - val_loss: 2.5476e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 2.5057e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.5508e-04 - accuracy: 1.0000 - val_loss: 2.4010e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.3986e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.4038e-04 - accuracy: 1.0000 - val_loss: 2.2626e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 2.2357e-04 - accuracy: 1.0000\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.2635e-04 - accuracy: 1.0000 - val_loss: 2.1299e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.1256e-04 - accuracy: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.1316e-04 - accuracy: 1.0000 - val_loss: 1.9981e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.9793e-04 - accuracy: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.0059e-04 - accuracy: 1.0000 - val_loss: 1.8821e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8904e-04 - accuracy: 1.0000\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.8904e-04 - accuracy: 1.0000 - val_loss: 1.7683e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 1.7460e-04 - accuracy: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.7797e-04 - accuracy: 1.0000 - val_loss: 1.6635e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.6796e-04 - accuracy: 1.0000\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.6796e-04 - accuracy: 1.0000 - val_loss: 1.5655e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 1.5727e-04 - accuracy: 1.0000\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.5818e-04 - accuracy: 1.0000 - val_loss: 1.4753e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.4924e-04 - accuracy: 1.0000\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.4929e-04 - accuracy: 1.0000 - val_loss: 1.3905e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 1.4373e-04 - accuracy: 1.0000\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.4099e-04 - accuracy: 1.0000 - val_loss: 1.3090e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.3300e-04 - accuracy: 1.0000\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.3300e-04 - accuracy: 1.0000 - val_loss: 1.2359e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.2623e-04 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.2560e-04 - accuracy: 1.0000 - val_loss: 1.1662e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 1.1607e-04 - accuracy: 1.0000\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.1869e-04 - accuracy: 1.0000 - val_loss: 1.1010e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 1.1107e-04 - accuracy: 1.0000\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.1225e-04 - accuracy: 1.0000 - val_loss: 1.0406e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 1.0796e-04 - accuracy: 1.0000\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.0617e-04 - accuracy: 1.0000 - val_loss: 9.8222e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 1.0037e-04 - accuracy: 1.0000\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.0049e-04 - accuracy: 1.0000 - val_loss: 9.2879e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 9.5357e-05 - accuracy: 1.0000\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 9.5109e-05 - accuracy: 1.0000 - val_loss: 8.7978e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 8.9478e-05 - accuracy: 1.0000\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 9.0152e-05 - accuracy: 1.0000 - val_loss: 8.3290e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 8.6337e-05 - accuracy: 1.0000\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 8.5462e-05 - accuracy: 1.0000 - val_loss: 7.8913e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 8.3288e-05 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 8.1081e-05 - accuracy: 1.0000 - val_loss: 7.4820e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 7.5767e-05 - accuracy: 1.0000\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 7.6953e-05 - accuracy: 1.0000 - val_loss: 7.1006e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 7.5398e-05 - accuracy: 1.0000\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 7.3095e-05 - accuracy: 1.0000 - val_loss: 6.7297e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 7.0336e-05 - accuracy: 1.0000\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 6.9359e-05 - accuracy: 1.0000 - val_loss: 6.3927e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 6.4488e-05 - accuracy: 1.0000\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 6.5930e-05 - accuracy: 1.0000 - val_loss: 6.0821e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 6.2877e-05 - accuracy: 1.0000\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 6.2690e-05 - accuracy: 1.0000 - val_loss: 5.7629e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 6.0638e-05 - accuracy: 1.0000\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 5.9597e-05 - accuracy: 1.0000 - val_loss: 5.4841e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.6463e-05 - accuracy: 1.0000\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 5.6753e-05 - accuracy: 1.0000 - val_loss: 5.2245e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 5.4040e-05 - accuracy: 1.0000\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 5.3970e-05 - accuracy: 1.0000 - val_loss: 4.9596e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 5.0075e-05 - accuracy: 1.0000\n",
      "Epoch 83: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 5.1338e-05 - accuracy: 1.0000 - val_loss: 4.7225e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 4.9076e-05 - accuracy: 1.0000\n",
      "Epoch 84: val_accuracy did not improve from 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 6ms/step - loss: 4.8904e-05 - accuracy: 1.0000 - val_loss: 4.4921e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 4.6508e-05 - accuracy: 1.0000\n",
      "Epoch 85: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.6571e-05 - accuracy: 1.0000 - val_loss: 4.2782e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 4.3691e-05 - accuracy: 1.0000\n",
      "Epoch 86: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.4371e-05 - accuracy: 1.0000 - val_loss: 4.0749e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 4.3004e-05 - accuracy: 1.0000\n",
      "Epoch 87: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.2283e-05 - accuracy: 1.0000 - val_loss: 3.8828e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 4.0993e-05 - accuracy: 1.0000\n",
      "Epoch 88: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 4.0343e-05 - accuracy: 1.0000 - val_loss: 3.7014e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 3.9660e-05 - accuracy: 1.0000\n",
      "Epoch 89: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.8456e-05 - accuracy: 1.0000 - val_loss: 3.5285e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.6704e-05 - accuracy: 1.0000\n",
      "Epoch 90: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.6704e-05 - accuracy: 1.0000 - val_loss: 3.3656e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 3.5070e-05 - accuracy: 1.0000\n",
      "Epoch 91: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.4981e-05 - accuracy: 1.0000 - val_loss: 3.2086e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 3.2088e-05 - accuracy: 1.0000\n",
      "Epoch 92: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.3350e-05 - accuracy: 1.0000 - val_loss: 3.0656e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 3.2101e-05 - accuracy: 1.0000\n",
      "Epoch 93: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.1841e-05 - accuracy: 1.0000 - val_loss: 2.9252e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 3.2128e-05 - accuracy: 1.0000\n",
      "Epoch 94: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 3.0431e-05 - accuracy: 1.0000 - val_loss: 2.7914e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 2.8825e-05 - accuracy: 1.0000\n",
      "Epoch 95: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.9032e-05 - accuracy: 1.0000 - val_loss: 2.6630e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 2.7069e-05 - accuracy: 1.0000\n",
      "Epoch 96: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.7742e-05 - accuracy: 1.0000 - val_loss: 2.5457e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 2.6343e-05 - accuracy: 1.0000\n",
      "Epoch 97: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.6505e-05 - accuracy: 1.0000 - val_loss: 2.4318e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 2.5583e-05 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.5328e-05 - accuracy: 1.0000 - val_loss: 2.3206e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 2.3763e-05 - accuracy: 1.0000\n",
      "Epoch 99: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.4171e-05 - accuracy: 1.0000 - val_loss: 2.2186e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 2.3404e-05 - accuracy: 1.0000\n",
      "Epoch 100: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 2.3143e-05 - accuracy: 1.0000 - val_loss: 2.1179e-05 - val_accuracy: 1.0000\n",
      "Runtime: 47 초\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "tf.random.set_seed(SEED) # Global seed, 가중치, 편향이 일정하게 변경됨\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=25, activation='relu')) # 기울기 소실 방지\n",
    "model.add(Dense(10, activation='relu')) # 기울기 소실 방지\n",
    "model.add(Dense(5, activation='softmax')) # 0 ~ 1사이의 확률, 합 1\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "es= EarlyStopping(monitor='loss', patience=1, restore_best_weights=True)\n",
    "\n",
    "mcp= ModelCheckpoint(filepath='./Pinterest.h5', monitor='val_accuracy',\n",
    "                    verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), shuffle=True,\n",
    "                epochs=100, batch_size=1, callbacks=[es, mcp])\n",
    "end=time.time()\n",
    "print('Runtime: {0:.0f} 초'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a074fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "acc_ax = loss_ax.twinx()   # 오른쪽 y 축 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 1.5]) # 값을 반영하여 변경\n",
    "\n",
    "# 오른쪽 y 축 설정\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "acc_ax.set_ylim([0.0, 1.3267]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6afa1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값: 2.117921394528821e-05 /정확도: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# verbose=0: 처리과정의 메시지 생략\n",
    "test_loss, test_acc = model.evaluate(x_val, y_val, batch_size=1, verbose=0)\n",
    "print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451b3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./Pinterest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b2ef106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터: (10, 25)\n",
      "p.shape: (10, 5)\n",
      "데이터: [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "# Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2\n",
    "print('데이터:', x_test.shape) # 변수 4개 12건\n",
    "p = model.predict(x_test)     # 테스트 데이터는 12건이고 3가지 확률에 속함.\n",
    "print('p.shape:', p.shape)    # (12, 3): 3: 폼종의 갯수\n",
    "print('데이터:', x_test[0])   # 첫번째 데이터행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f933b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0.04628954 0.01695444 0.03809654 0.8874883  0.01117121]\n",
      "예측값의 합: 1.000\n",
      "예측값: 4.63% 1.70% 3.81% 88.75% 1.12%\n",
      "One-hot-encoding:  [0. 0. 0. 1. 0.]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print('예측값:', p[0])       # 확률 0 ~ 1사이의 실수값\n",
    "print('예측값의 합: {0:0.3f}'.format(np.sum(p[0])))\n",
    "print('예측값: {0:.2f}% {1:.2f}% {2:.2f}% {3:.2f}% {4:.2f}%'.format(p[0,0]*100,p[0,1]*100,p[0,2]*100,p[0,3]*100,p[0,4]*100))\n",
    "print('One-hot-encoding: ', y_test[0])\n",
    "print(np.argmax(p[0]))      # 가장 큰값의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab9fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04628954 0.01695444 0.03809654 0.8874883  0.01117121]\n",
      " [0.00907909 0.64618486 0.2732731  0.04202783 0.02943517]\n",
      " [0.6499225  0.00782874 0.01280041 0.12066939 0.20877893]\n",
      " [0.00825434 0.24442564 0.71000594 0.031867   0.00544701]\n",
      " [0.31513578 0.11863916 0.08782674 0.15214723 0.32625112]\n",
      " [0.31513578 0.11863916 0.08782674 0.15214723 0.32625112]\n",
      " [0.04628954 0.01695444 0.03809654 0.8874883  0.01117121]\n",
      " [0.6499225  0.00782874 0.01280041 0.12066939 0.20877893]\n",
      " [0.00825434 0.24442564 0.71000594 0.031867   0.00544701]\n",
      " [0.00907909 0.64618486 0.2732731  0.04202783 0.02943517]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644628b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
