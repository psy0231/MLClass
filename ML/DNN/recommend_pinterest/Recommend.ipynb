{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66382efe",
   "metadata": {},
   "source": [
    "## 추천 시스템: 5종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f86910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "# import cv2\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용\n",
    "from tensorflow.keras.layers import Dense       # 전결합\n",
    "from tensorflow.keras.layers import Dropout     # 특정 node를 사용안함.\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping   # 학습 자동 중지\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # 우수한 학습 모델 파일 저장\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.utils import to_categorical   # one-hot 엔코딩\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split # 학습셋과 테스트셋의 분리 지원\n",
    "from sklearn.model_selection import StratifiedKFold  # K겹 교차 검증\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "import platform \n",
    "# Windows, Linux, Darwin\n",
    "if (platform.system() == 'Windows'):  \n",
    "    rc('font', family=font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name())\n",
    "    path = '.' # Local\n",
    "else:    \n",
    "    rc('font', family='NanumBarunGothic')  # Ubuntu 18.04 기준 한글 처리\n",
    "    path = '/content/drive/My Drive/kd_ml/dnn/iris' # Colab\n",
    "\n",
    "os.chdir(path) # 기본 경로 설정\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12         # 글자 크기\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4) # 10:4의 그래프 비율\n",
    "plt.rcParams['axes.unicode_minus'] = False  # minus 부호는 unicode 적용시 한글이 깨짐으로 설정\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# gpu 사용시 런타임에서 필요한 양만큼의 GPU 메모리를 할당후 자동 증가 처리\n",
    "# OS 메모리도 초기화됨.\n",
    "# ---------------------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "    \n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7ead2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 26)\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      "  0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('./train.csv', delimiter=',', skiprows=1, dtype=np.float64)\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28faee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 25)\n",
      "(100,)\n",
      "[0. 1. 2. 3. 4. 0. 1. 2. 3. 4. 0. 1. 2. 3. 4.]\n",
      "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "X = data[:, 0:25]  # 독립 변수 25개\n",
    "Y = data[:, 25]    # 종속 변수, 26번째, 답\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y[:15])\n",
    "Y = Y.astype('int')\n",
    "print(Y[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e76610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0.]\n",
      "Y[0]: 0\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "Y_encoded = to_categorical(Y) \n",
    "print(X[0])              # Iris-setosa  0  [5.1 3.5 1.4 0.2]\n",
    "print('Y[0]:', Y[0])     # Y[0]의 값 0은 1 이 위치할 index로 사용 ★\n",
    "print(Y_encoded[0:5])      # Y[0]의 값 0은 1 이 위치할 index로 사용 ★"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de4be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "(18, 5)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 분할을 통한 훈련, 검증, 테스트 데이터의 분리\n",
    "seed = 0\n",
    "# 90%: 분할대기, 10%: 테스트\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(X, Y_encoded,\n",
    "                                                        stratify=Y_encoded,\n",
    "                                                        test_size=0.1,\n",
    "                                                        random_state=seed)\n",
    "# 나머지 데이터 90%를 분할, 80%: 훈련, 20%: 검증\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  stratify=y_train_all,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=seed)\n",
    "\n",
    "print(y_val)\n",
    "print(y_val.shape)\n",
    "# Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc2bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                520       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/72 [================>.............] - ETA: 0s - loss: 1.3898 - accuracy: 0.2143     \n",
      "Epoch 1: val_accuracy improved from -inf to 0.38889, saving model to .\\Pinterest.h5\n",
      "72/72 [==============================] - 1s 4ms/step - loss: 1.3088 - accuracy: 0.2500 - val_loss: 1.1295 - val_accuracy: 0.3889\n",
      "Epoch 2/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 1.0253 - accuracy: 0.5000    \n",
      "Epoch 2: val_accuracy did not improve from 0.38889\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.4028 - val_loss: 0.8951 - val_accuracy: 0.3889\n",
      "Epoch 3/100\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.8793 - accuracy: 0.6852    \n",
      "Epoch 3: val_accuracy improved from 0.38889 to 0.83333, saving model to .\\Pinterest.h5\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8343 - accuracy: 0.7083 - val_loss: 0.6980 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "41/72 [================>.............] - ETA: 0s - loss: 0.7502 - accuracy: 0.7073    \n",
      "Epoch 4: val_accuracy improved from 0.83333 to 1.00000, saving model to .\\Pinterest.h5\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.7917 - val_loss: 0.4631 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "35/72 [=============>................] - ETA: 0s - loss: 0.4457 - accuracy: 1.0000\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.2327 - accuracy: 1.0000\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 0.1263 - accuracy: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 1.0000\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "37/72 [==============>...............] - ETA: 0s - loss: 0.0482 - accuracy: 1.0000\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "33/72 [============>.................] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "41/72 [================>.............] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "43/72 [================>.............] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "43/72 [================>.............] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "56/72 [======================>.......] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "40/72 [===============>..............] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 9.8570e-04 - accuracy: 1.0000 - val_loss: 9.2721e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 9.2752e-04 - accuracy: 1.0000\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 9.1249e-04 - accuracy: 1.0000 - val_loss: 8.5643e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "40/72 [===============>..............] - ETA: 0s - loss: 8.2797e-04 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 8.4309e-04 - accuracy: 1.0000 - val_loss: 7.9236e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 7.8312e-04 - accuracy: 1.0000\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 7.8158e-04 - accuracy: 1.0000 - val_loss: 7.3538e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 7.2419e-04 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 7.2652e-04 - accuracy: 1.0000 - val_loss: 6.8340e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 6.9961e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 6.7548e-04 - accuracy: 1.0000 - val_loss: 6.3570e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 6.1125e-04 - accuracy: 1.0000\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 6.2857e-04 - accuracy: 1.0000 - val_loss: 5.9338e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 5.6968e-04 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.8623e-04 - accuracy: 1.0000 - val_loss: 5.5202e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 5.2320e-04 - accuracy: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.4550e-04 - accuracy: 1.0000 - val_loss: 5.1547e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 5.4087e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.1005e-04 - accuracy: 1.0000 - val_loss: 4.8181e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 4.6546e-04 - accuracy: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.7732e-04 - accuracy: 1.0000 - val_loss: 4.5194e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 4.6503e-04 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.4712e-04 - accuracy: 1.0000 - val_loss: 4.2196e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 4.2607e-04 - accuracy: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 4.1781e-04 - accuracy: 1.0000 - val_loss: 3.9460e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 3.9645e-04 - accuracy: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.9150e-04 - accuracy: 1.0000 - val_loss: 3.6969e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 3.7095e-04 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.6754e-04 - accuracy: 1.0000 - val_loss: 3.4677e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 3.4641e-04 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.4535e-04 - accuracy: 1.0000 - val_loss: 3.2615e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 3.4418e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.2529e-04 - accuracy: 1.0000 - val_loss: 3.0608e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 3.1426e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 3.0527e-04 - accuracy: 1.0000 - val_loss: 2.8799e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 2.9399e-04 - accuracy: 1.0000\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.8737e-04 - accuracy: 1.0000 - val_loss: 2.7093e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 2.7778e-04 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.7052e-04 - accuracy: 1.0000 - val_loss: 2.5473e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "40/72 [===============>..............] - ETA: 0s - loss: 2.3703e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.5505e-04 - accuracy: 1.0000 - val_loss: 2.4002e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "40/72 [===============>..............] - ETA: 0s - loss: 2.4130e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.4034e-04 - accuracy: 1.0000 - val_loss: 2.2626e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "59/72 [=======================>......] - ETA: 0s - loss: 2.2173e-04 - accuracy: 1.0000\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.2629e-04 - accuracy: 1.0000 - val_loss: 2.1285e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 2.2481e-04 - accuracy: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 2.1310e-04 - accuracy: 1.0000 - val_loss: 1.9981e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "45/72 [=================>............] - ETA: 0s - loss: 1.9214e-04 - accuracy: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.0053e-04 - accuracy: 1.0000 - val_loss: 1.8815e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 1.9598e-04 - accuracy: 1.0000\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.8896e-04 - accuracy: 1.0000 - val_loss: 1.7678e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 1.7567e-04 - accuracy: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.7791e-04 - accuracy: 1.0000 - val_loss: 1.6622e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 1.7768e-04 - accuracy: 1.0000\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.6790e-04 - accuracy: 1.0000 - val_loss: 1.5647e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "33/72 [============>.................] - ETA: 0s - loss: 1.5672e-04 - accuracy: 1.0000\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.5811e-04 - accuracy: 1.0000 - val_loss: 1.4742e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 1.4627e-04 - accuracy: 1.0000\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4919e-04 - accuracy: 1.0000 - val_loss: 1.3894e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 1.4938e-04 - accuracy: 1.0000\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4089e-04 - accuracy: 1.0000 - val_loss: 1.3082e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 1.3183e-04 - accuracy: 1.0000\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3293e-04 - accuracy: 1.0000 - val_loss: 1.2345e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 1.3239e-04 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2548e-04 - accuracy: 1.0000 - val_loss: 1.1648e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 1.1266e-04 - accuracy: 1.0000\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1859e-04 - accuracy: 1.0000 - val_loss: 1.0996e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 1.1008e-04 - accuracy: 1.0000\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1213e-04 - accuracy: 1.0000 - val_loss: 1.0390e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 1.0637e-04 - accuracy: 1.0000\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0607e-04 - accuracy: 1.0000 - val_loss: 9.8143e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 9.6632e-05 - accuracy: 1.0000\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: 9.2773e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 9.3757e-05 - accuracy: 1.0000\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 9.5006e-05 - accuracy: 1.0000 - val_loss: 8.7892e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 9.0621e-05 - accuracy: 1.0000\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 9.0058e-05 - accuracy: 1.0000 - val_loss: 8.3157e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "41/72 [================>.............] - ETA: 0s - loss: 8.8925e-05 - accuracy: 1.0000\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 8.5364e-05 - accuracy: 1.0000 - val_loss: 7.8780e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "42/72 [================>.............] - ETA: 0s - loss: 8.2188e-05 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 8.0994e-05 - accuracy: 1.0000 - val_loss: 7.4741e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "59/72 [=======================>......] - ETA: 0s - loss: 7.3351e-05 - accuracy: 1.0000\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 7.6875e-05 - accuracy: 1.0000 - val_loss: 7.0906e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 7.6160e-05 - accuracy: 1.0000\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 7.3012e-05 - accuracy: 1.0000 - val_loss: 6.7191e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "56/72 [======================>.......] - ETA: 0s - loss: 7.3198e-05 - accuracy: 1.0000\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 6.9281e-05 - accuracy: 1.0000 - val_loss: 6.3854e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 6.4044e-05 - accuracy: 1.0000\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 6.5859e-05 - accuracy: 1.0000 - val_loss: 6.0721e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 6.3597e-05 - accuracy: 1.0000\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 6.2612e-05 - accuracy: 1.0000 - val_loss: 5.7543e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 6.0146e-05 - accuracy: 1.0000\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.9516e-05 - accuracy: 1.0000 - val_loss: 5.4788e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 5.4004e-05 - accuracy: 1.0000\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.6684e-05 - accuracy: 1.0000 - val_loss: 5.2192e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 5.4002e-05 - accuracy: 1.0000\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.3909e-05 - accuracy: 1.0000 - val_loss: 4.9543e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "42/72 [================>.............] - ETA: 0s - loss: 5.5300e-05 - accuracy: 1.0000\n",
      "Epoch 83: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 5.1267e-05 - accuracy: 1.0000 - val_loss: 4.7172e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "39/72 [===============>..............] - ETA: 0s - loss: 4.5353e-05 - accuracy: 1.0000\n",
      "Epoch 84: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.8841e-05 - accuracy: 1.0000 - val_loss: 4.4848e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 4.9004e-05 - accuracy: 1.0000\n",
      "Epoch 85: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.6515e-05 - accuracy: 1.0000 - val_loss: 4.2755e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "45/72 [=================>............] - ETA: 0s - loss: 4.3394e-05 - accuracy: 1.0000\n",
      "Epoch 86: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.4313e-05 - accuracy: 1.0000 - val_loss: 4.0676e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 4.2056e-05 - accuracy: 1.0000\n",
      "Epoch 87: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.2229e-05 - accuracy: 1.0000 - val_loss: 3.8749e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/72 [==============>...............] - ETA: 0s - loss: 4.8002e-05 - accuracy: 1.0000\n",
      "Epoch 88: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 4.0288e-05 - accuracy: 1.0000 - val_loss: 3.6921e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 3.8480e-05 - accuracy: 1.0000\n",
      "Epoch 89: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.8411e-05 - accuracy: 1.0000 - val_loss: 3.5232e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 4.1546e-05 - accuracy: 1.0000\n",
      "Epoch 90: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.6654e-05 - accuracy: 1.0000 - val_loss: 3.3630e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 3.6168e-05 - accuracy: 1.0000\n",
      "Epoch 91: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.4944e-05 - accuracy: 1.0000 - val_loss: 3.2033e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 3.1454e-05 - accuracy: 1.0000\n",
      "Epoch 92: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.3315e-05 - accuracy: 1.0000 - val_loss: 3.0583e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 3.2874e-05 - accuracy: 1.0000\n",
      "Epoch 93: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.1808e-05 - accuracy: 1.0000 - val_loss: 2.9192e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 2.8629e-05 - accuracy: 1.0000\n",
      "Epoch 94: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 3.0383e-05 - accuracy: 1.0000 - val_loss: 2.7841e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 2.8405e-05 - accuracy: 1.0000\n",
      "Epoch 95: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.9005e-05 - accuracy: 1.0000 - val_loss: 2.6630e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 2.6154e-05 - accuracy: 1.0000\n",
      "Epoch 96: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.7707e-05 - accuracy: 1.0000 - val_loss: 2.5404e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "44/72 [=================>............] - ETA: 0s - loss: 2.7691e-05 - accuracy: 1.0000\n",
      "Epoch 97: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.6462e-05 - accuracy: 1.0000 - val_loss: 2.4272e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.5201e-05 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.5308e-05 - accuracy: 1.0000 - val_loss: 2.3179e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "34/72 [=============>................] - ETA: 0s - loss: 2.6818e-05 - accuracy: 1.0000\n",
      "Epoch 99: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.4144e-05 - accuracy: 1.0000 - val_loss: 2.2159e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 2.3580e-05 - accuracy: 1.0000\n",
      "Epoch 100: val_accuracy did not improve from 1.00000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.3087e-05 - accuracy: 1.0000 - val_loss: 2.1179e-05 - val_accuracy: 1.0000\n",
      "Runtime: 14 초\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "tf.random.set_seed(SEED) # Global seed, 가중치, 편향이 일정하게 변경됨\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=25, activation='relu')) # 기울기 소실 방지\n",
    "model.add(Dense(10, activation='relu')) # 기울기 소실 방지\n",
    "model.add(Dense(5, activation='softmax')) # 0 ~ 1사이의 확률, 합 1\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "es= EarlyStopping(monitor='loss', patience=1, restore_best_weights=True)\n",
    "\n",
    "mcp= ModelCheckpoint(filepath='./Pinterest.h5', monitor='val_accuracy',\n",
    "                    verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), shuffle=True,\n",
    "                epochs=100, batch_size=1, callbacks=[es, mcp])\n",
    "end=time.time()\n",
    "print('Runtime: {0:.0f} 초'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a074fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "acc_ax = loss_ax.twinx()   # 오른쪽 y 축 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 1.5]) # 값을 반영하여 변경\n",
    "\n",
    "# 오른쪽 y 축 설정\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "acc_ax.set_ylim([0.0, 1.3267]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afa1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값: 2.117921394528821e-05 /정확도: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# verbose=0: 처리과정의 메시지 생략\n",
    "test_loss, test_acc = model.evaluate(x_val, y_val, batch_size=1, verbose=0)\n",
    "print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451b3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./Pinterest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2ef106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터: (10, 25)\n",
      "p.shape: (10, 5)\n",
      "데이터: [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "# Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2\n",
    "print('데이터:', x_test.shape) # 변수 4개 12건\n",
    "p = model.predict(x_test)     # 테스트 데이터는 12건이고 3가지 확률에 속함.\n",
    "print('p.shape:', p.shape)    # (12, 3): 3: 폼종의 갯수\n",
    "print('데이터:', x_test[0])   # 첫번째 데이터행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f933b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0.04628957 0.01695444 0.03809656 0.88748825 0.01117123]\n",
      "예측값의 합: 1.000\n",
      "예측값: 4.63% 1.70% 3.81% 88.75% 1.12%\n",
      "One-hot-encoding:  [0. 0. 0. 1. 0.]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print('예측값:', p[0])       # 확률 0 ~ 1사이의 실수값\n",
    "print('예측값의 합: {0:0.3f}'.format(np.sum(p[0])))\n",
    "print('예측값: {0:.2f}% {1:.2f}% {2:.2f}% {3:.2f}% {4:.2f}%'.format(p[0,0]*100,p[0,1]*100,p[0,2]*100,p[0,3]*100,p[0,4]*100))\n",
    "print('One-hot-encoding: ', y_test[0])\n",
    "print(np.argmax(p[0]))      # 가장 큰값의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab9fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04628957 0.01695444 0.03809656 0.88748825 0.01117123]\n",
      " [0.0090791  0.6461846  0.27327323 0.04202784 0.02943519]\n",
      " [0.6499224  0.00782875 0.01280042 0.12066945 0.20877898]\n",
      " [0.00825434 0.24442565 0.71000594 0.03186703 0.00544702]\n",
      " [0.31513578 0.11863917 0.08782677 0.15214728 0.32625097]\n",
      " [0.31513578 0.11863917 0.08782677 0.15214728 0.32625097]\n",
      " [0.04628957 0.01695444 0.03809656 0.88748825 0.01117123]\n",
      " [0.6499224  0.00782875 0.01280042 0.12066945 0.20877898]\n",
      " [0.00825434 0.24442565 0.71000594 0.03186703 0.00544702]\n",
      " [0.0090791  0.6461846  0.27327323 0.04202784 0.02943519]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644628b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
